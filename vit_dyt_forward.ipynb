{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Initialize ViT-B/16 from scratch, optionally convert LN -> DynamicTanh (DyT)\n",
        "\n",
        "import os\n",
        "from types import SimpleNamespace\n",
        "\n",
        "import torch\n",
        "from timm.models import create_model\n",
        "\n",
        "from datasets import build_dataset  # uses repo's timm create_transform + ImageNet-style norms\n",
        "from dynamic_tanh import convert_ln_to_dyt\n",
        "\n",
        "# --- user knobs ---\n",
        "MODEL_NAME = \"vit_base_patch16_224\"   # timm model name\n",
        "USE_DYT = True                        # toggle DyT on/off\n",
        "BATCH_SIZE = 4\n",
        "DATA_SET = \"IMNET\"                    # 'IMNET' | 'CIFAR' | 'image_folder'\n",
        "DATA_PATH = os.environ.get(\"IMAGENET_PATH\", \"/path/to/imagenet\")  # expects train/val subfolders for IMNET\n",
        "EVAL_DATA_PATH = None                 # only used for data_set='image_folder'\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# match repo init style (main.py): create_model(..., pretrained=False, num_classes, global_pool='avg', drop_path_rate)\n",
        "model = create_model(\n",
        "    MODEL_NAME,\n",
        "    pretrained=False,\n",
        "    num_classes=1000,\n",
        "    global_pool=\"avg\",\n",
        "    drop_path_rate=0.0,\n",
        ")\n",
        "\n",
        "if USE_DYT:\n",
        "    model = convert_ln_to_dyt(model)\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Build dataset with the repo's transforms and get one batch (B=4)\n",
        "\n",
        "# Minimal args needed by datasets.build_dataset/build_transform\n",
        "args = SimpleNamespace(\n",
        "    # dataset selection\n",
        "    data_set=DATA_SET,\n",
        "    data_path=DATA_PATH,\n",
        "    eval_data_path=EVAL_DATA_PATH,\n",
        "    nb_classes=1000,\n",
        "    # transform params (match defaults in main.py)\n",
        "    input_size=224,\n",
        "    imagenet_default_mean_and_std=True,\n",
        "    color_jitter=0.4,\n",
        "    aa=\"rand-m9-mstd0.5-inc1\",\n",
        "    train_interpolation=\"bicubic\",\n",
        "    reprob=0.25,\n",
        "    remode=\"pixel\",\n",
        "    recount=1,\n",
        "    crop_pct=None,\n",
        ")\n",
        "\n",
        "# This uses the same transform codepath as training in this repo\n",
        "train_dataset, nb_classes = build_dataset(is_train=True, args=args)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "samples, targets = next(iter(train_loader))\n",
        "print(\"samples:\", samples.shape, samples.dtype)\n",
        "print(\"targets:\", targets.shape, targets.dtype)\n",
        "(samples, targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Forward pass (same structure as repo training/validation)\n",
        "\n",
        "# training/eval code in engine.py does: samples = samples.to(device) ; output = model(samples)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    samples_device = samples.to(DEVICE, non_blocking=False)\n",
        "    outputs = model(samples_device)\n",
        "\n",
        "print(\"outputs:\", outputs.shape, outputs.dtype, \"device:\", outputs.device)\n",
        "outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Inspect patch embeddings, positional embeddings, and their combination (matches timm logic)\n",
        "\n",
        "from timm.layers import resample_abs_pos_embed\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_img = samples.to(DEVICE, non_blocking=False)\n",
        "\n",
        "    # 1) Patch embeddings (same as: x = self.patch_embed(x))\n",
        "    x_patch = model.patch_embed(x_img)\n",
        "\n",
        "    # 2) Positional embedding tensor used (same as inside VisionTransformer._pos_embed)\n",
        "    if model.pos_embed is None:\n",
        "        pos_embed_used = None\n",
        "    else:\n",
        "        if getattr(model, \"dynamic_img_size\", False):\n",
        "            # dynamic_img_size path expects NHWC patch output\n",
        "            B, H, W, C = x_patch.shape\n",
        "            prev_grid_size = model.patch_embed.grid_size\n",
        "            pos_embed_used = resample_abs_pos_embed(\n",
        "                model.pos_embed,\n",
        "                new_size=(H, W),\n",
        "                old_size=prev_grid_size,\n",
        "                num_prefix_tokens=0 if model.no_embed_class else model.num_prefix_tokens,\n",
        "            )\n",
        "        else:\n",
        "            pos_embed_used = model.pos_embed\n",
        "\n",
        "    # 3) Combined tokens (same as: x = self._pos_embed(x_patch); x includes prefix tokens and pos add)\n",
        "    if model.pos_embed is None:\n",
        "        # timm returns flattened tokens when no pos_embed\n",
        "        if x_patch.ndim == 4:\n",
        "            B, H, W, C = x_patch.shape\n",
        "            x_tokens = x_patch.view(B, -1, C)\n",
        "        else:\n",
        "            x_tokens = x_patch\n",
        "    else:\n",
        "        # handle NHWC -> NLC flatten if needed (matches timm dynamic_img_size branch)\n",
        "        if getattr(model, \"dynamic_img_size\", False):\n",
        "            B, H, W, C = x_patch.shape\n",
        "            x_tokens = x_patch.view(B, -1, C)\n",
        "        else:\n",
        "            x_tokens = x_patch\n",
        "\n",
        "        to_cat = []\n",
        "        if getattr(model, \"cls_token\", None) is not None:\n",
        "            to_cat.append(model.cls_token.expand(x_tokens.shape[0], -1, -1))\n",
        "        if getattr(model, \"reg_token\", None) is not None:\n",
        "            to_cat.append(model.reg_token.expand(x_tokens.shape[0], -1, -1))\n",
        "\n",
        "        if model.no_embed_class:\n",
        "            # add pos to patch tokens only, then concat prefix\n",
        "            x_tokens = x_tokens + pos_embed_used\n",
        "            if to_cat:\n",
        "                x_tokens = torch.cat(to_cat + [x_tokens], dim=1)\n",
        "        else:\n",
        "            # concat prefix first, then add pos_embed (pos_embed includes prefix positions)\n",
        "            if to_cat:\n",
        "                x_tokens = torch.cat(to_cat + [x_tokens], dim=1)\n",
        "            x_tokens = x_tokens + pos_embed_used\n",
        "\n",
        "        # timm returns self.pos_drop(x)\n",
        "        x_tokens = model.pos_drop(x_tokens)\n",
        "\n",
        "# Report shapes\n",
        "print(\"x_patch shape:\", tuple(x_patch.shape))\n",
        "print(\"pos_embed_used shape:\", None if pos_embed_used is None else tuple(pos_embed_used.shape))\n",
        "print(\"x_tokens (after pos add + prefix concat + pos_drop) shape:\", tuple(x_tokens.shape))\n",
        "\n",
        "# Expose all three\n",
        "x_patch, pos_embed_used, x_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Re-initialize all DyT alphas to a new alpha_init_value\n",
        "\n",
        "from dynamic_tanh import DynamicTanh\n",
        "\n",
        "NEW_ALPHA_INIT_VALUE = 0.8  # <-- set whatever you want\n",
        "\n",
        "# Re-init DyT alpha parameters in-place\n",
        "num_dyt = 0\n",
        "with torch.no_grad():\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, DynamicTanh):\n",
        "            # keep the module's metadata consistent\n",
        "            m.alpha_init_value = float(NEW_ALPHA_INIT_VALUE)\n",
        "            # overwrite the learnable parameter value\n",
        "            m.alpha.data.fill_(float(NEW_ALPHA_INIT_VALUE))\n",
        "            num_dyt += 1\n",
        "\n",
        "print(f\"Reinitialized {num_dyt} DynamicTanh modules with alpha={NEW_ALPHA_INIT_VALUE}\")\n",
        "\n",
        "# sanity check: show a few alpha values\n",
        "alphas = [m.alpha.item() for m in model.modules() if isinstance(m, DynamicTanh)]\n",
        "print(\"first 5 alphas:\", alphas[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Cache inputs to each DynamicTanh in forward order + cosine similarity/angle vs previous\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dynamic_tanh import DynamicTanh\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# We'll store DyT inputs in the order they're executed\n",
        "_dyt_inputs = []          # list[torch.Tensor] on CPU\n",
        "_dyt_names = []           # list[str]\n",
        "_dyt_kinds = []           # list[str]  'tokens' or 'pooled'\n",
        "_handles = []\n",
        "\n",
        "# forward_pre_hook captures module inputs\n",
        "\n",
        "def _make_dyt_pre_hook(name: str):\n",
        "    def _hook(mod, inputs):\n",
        "        x = inputs[0]\n",
        "        # token-level DyTs see [B, N, C]; fc_norm DyT sees [B, C]\n",
        "        if x.ndim == 3:\n",
        "            kind = \"tokens\"\n",
        "            x_use = x.detach().cpu()\n",
        "        elif x.ndim == 2:\n",
        "            kind = \"pooled\"\n",
        "            # normalize to [B, 1, C] so we can store consistently\n",
        "            x_use = x.detach().cpu().unsqueeze(1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected DyT input ndim={x.ndim} for {name}\")\n",
        "\n",
        "        _dyt_inputs.append(x_use)\n",
        "        _dyt_names.append(name)\n",
        "        _dyt_kinds.append(kind)\n",
        "\n",
        "    return _hook\n",
        "\n",
        "for name, m in model.named_modules():\n",
        "    if isinstance(m, DynamicTanh):\n",
        "        _handles.append(m.register_forward_pre_hook(_make_dyt_pre_hook(name)))\n",
        "\n",
        "# Run forward\n",
        "with torch.no_grad():\n",
        "    _ = model(samples.to(DEVICE, non_blocking=False))\n",
        "\n",
        "# Remove hooks\n",
        "for h in _handles:\n",
        "    h.remove()\n",
        "\n",
        "# Compute cosine similarities vs previous DyT (exclude CLS token position for token-level tensors)\n",
        "EPS = 1e-8\n",
        "B = _dyt_inputs[0].shape[0]\n",
        "max_S = max(t.shape[1] for t in _dyt_inputs)  # includes cls for token-level; pooled has S=1\n",
        "L = len(_dyt_inputs)\n",
        "\n",
        "# We'll store padded [B, L, max_S] (NaN where not applicable)\n",
        "cos_sims = torch.full((B, L, max_S), float('nan'))\n",
        "angles = torch.full((B, L, max_S), float('nan'))\n",
        "\n",
        "# Also keep per-layer unpadded dicts (keyed by DyT execution index)\n",
        "cos_sims_by_dyt = {}\n",
        "angles_by_dyt = {}\n",
        "\n",
        "for i in range(L):\n",
        "    cur = _dyt_inputs[i]  # [B, S_cur, C]\n",
        "\n",
        "    if i == 0:\n",
        "        continue\n",
        "\n",
        "    prev = _dyt_inputs[i - 1]\n",
        "\n",
        "    # If current is pooled (S=1), pool previous token activations to match\n",
        "    if _dyt_kinds[i] == \"pooled\":\n",
        "        # previous might be tokens; if so, exclude CLS then avg pool\n",
        "        if prev.shape[1] > 1:\n",
        "            prev_vec = prev[:, 1:, :].mean(dim=1, keepdim=True)  # [B, 1, C]\n",
        "        else:\n",
        "            prev_vec = prev\n",
        "        cur_vec = cur  # already [B, 1, C]\n",
        "    else:\n",
        "        # token-level: align token grids and exclude CLS position\n",
        "        # current/prev token-level inputs should both include CLS at position 0\n",
        "        cur_vec = cur[:, 1:, :]  # [B, S-1, C]\n",
        "        prev_vec = prev[:, 1:, :] if prev.shape[1] > 1 else prev.expand_as(cur_vec)\n",
        "\n",
        "        # in case something changes shape, trim to min token length\n",
        "        S_min = min(cur_vec.shape[1], prev_vec.shape[1])\n",
        "        cur_vec = cur_vec[:, :S_min, :]\n",
        "        prev_vec = prev_vec[:, :S_min, :]\n",
        "\n",
        "    # cosine over embedding dim -> [B, S]\n",
        "    dot = (cur_vec * prev_vec).sum(dim=-1)\n",
        "    denom = cur_vec.norm(dim=-1) * prev_vec.norm(dim=-1) + EPS\n",
        "    c = dot / denom\n",
        "    c = c.clamp(-1.0, 1.0)\n",
        "    a = torch.acos(c)\n",
        "\n",
        "    # store\n",
        "    S = c.shape[1]\n",
        "    cos_sims[:, i, :S] = c\n",
        "    angles[:, i, :S] = a\n",
        "    cos_sims_by_dyt[i] = c\n",
        "    angles_by_dyt[i] = a\n",
        "\n",
        "# Plot: average over batch and sequence (excluding NaNs)\n",
        "mean_cos = torch.nanmean(cos_sims, dim=(0, 2)).numpy()   # [L]\n",
        "mean_ang = torch.nanmean(angles, dim=(0, 2)).numpy()     # [L]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(mean_cos, marker='o')\n",
        "plt.title('Average cosine similarity vs DyT execution index')\n",
        "plt.xlabel('DyT idx')\n",
        "plt.ylabel('avg cosine')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(mean_ang, marker='o')\n",
        "plt.title('Average angle (arccos) vs DyT execution index')\n",
        "plt.xlabel('DyT idx')\n",
        "plt.ylabel('avg angle (radians)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Captured {L} DynamicTanh inputs\")\n",
        "print(\"First few DyTs:\")\n",
        "for i in range(min(5, L)):\n",
        "    print(i, _dyt_names[i], _dyt_kinds[i], tuple(_dyt_inputs[i].shape))\n",
        "\n",
        "# Expose arrays + dicts\n",
        "cos_sims, angles, cos_sims_by_dyt, angles_by_dyt, _dyt_names, _dyt_kinds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Cache output of each transformer block and plot average activation norm vs block\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "\n",
        "_block_outputs = []   # list[torch.Tensor] on CPU, each [B, N, C]\n",
        "_block_names = []\n",
        "_handles = []\n",
        "\n",
        "def _make_block_hook(name: str):\n",
        "    def _hook(mod, inputs, output):\n",
        "        # output is [B, N, C]\n",
        "        _block_outputs.append(output.detach().cpu())\n",
        "        _block_names.append(name)\n",
        "    return _hook\n",
        "\n",
        "for i, blk in enumerate(model.blocks):\n",
        "    _handles.append(blk.register_forward_hook(_make_block_hook(f\"blocks.{i}\")))\n",
        "\n",
        "with torch.no_grad():\n",
        "    _ = model(samples.to(DEVICE, non_blocking=False))\n",
        "\n",
        "for h in _handles:\n",
        "    h.remove()\n",
        "\n",
        "# Compute average token-vector norm per block, excluding CLS token\n",
        "avg_norms = []\n",
        "for out in _block_outputs:\n",
        "    out_tok = out[:, 1:, :]  # [B, S, C] exclude CLS\n",
        "    token_norm = out_tok.norm(dim=-1)  # [B, S]\n",
        "    avg_norms.append(token_norm.mean().item())\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(avg_norms, marker='o')\n",
        "plt.title('Average activation norm vs transformer block')\n",
        "plt.xlabel('block idx')\n",
        "plt.ylabel('avg ||x||')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "avg_norms, _block_names\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Backward pass (training-style) + cache grads of each block output; plot grad norms\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.train()  # training-style backward\n",
        "\n",
        "# Capture block outputs (with gradients)\n",
        "_block_out_refs = []\n",
        "_handles = []\n",
        "\n",
        "def _make_block_hook_retain():\n",
        "    def _hook(mod, inputs, output):\n",
        "        # retain grads on block outputs\n",
        "        output.retain_grad()\n",
        "        _block_out_refs.append(output)\n",
        "    return _hook\n",
        "\n",
        "for blk in model.blocks:\n",
        "    _handles.append(blk.register_forward_hook(_make_block_hook_retain()))\n",
        "\n",
        "# Forward + loss + backward (same structure as engine.py full precision)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "model.zero_grad(set_to_none=True)\n",
        "\n",
        "samples_device = samples.to(DEVICE, non_blocking=False)\n",
        "targets_device = targets.to(DEVICE, non_blocking=False)\n",
        "\n",
        "outputs = model(samples_device)\n",
        "loss = criterion(outputs, targets_device)\n",
        "loss.backward()\n",
        "\n",
        "for h in _handles:\n",
        "    h.remove()\n",
        "\n",
        "# Compute average grad norm per block output (exclude CLS token)\n",
        "avg_grad_norms = []\n",
        "avg_log_grad_norms = []\n",
        "\n",
        "for out in _block_out_refs:\n",
        "    g = out.grad.detach().cpu()          # [B, N, C]\n",
        "    g_tok = g[:, 1:, :]                  # exclude CLS\n",
        "    token_gnorm = g_tok.norm(dim=-1)     # [B, S]\n",
        "\n",
        "    mean_g = token_gnorm.mean().item()\n",
        "    avg_grad_norms.append(mean_g)\n",
        "\n",
        "    # log(grad_norm) with small epsilon for stability\n",
        "    avg_log_grad_norms.append(torch.log(token_gnorm + 1e-12).mean().item())\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(avg_grad_norms, marker='o')\n",
        "plt.title('Average gradient norm vs transformer block output')\n",
        "plt.xlabel('block idx')\n",
        "plt.ylabel('avg ||dL/dx||')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(avg_log_grad_norms, marker='o')\n",
        "plt.title('Average log gradient norm vs transformer block output')\n",
        "plt.xlabel('block idx')\n",
        "plt.ylabel('avg log(||dL/dx||)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "loss.item(), avg_grad_norms, avg_log_grad_norms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Train via main.py (no re-implementation of training loop)\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import main as dyt_main\n",
        "\n",
        "# --- important knobs (similar to your block around lines 24-42) ---\n",
        "MODEL_NAME = \"vit_base_patch16_224\"\n",
        "EPOCHS = 10\n",
        "\n",
        "DATA_SET = \"CIFAR\"\n",
        "DATA_PATH = \"/tmp/cifar100\"      # CIFAR will download here\n",
        "NB_CLASSES = 100\n",
        "INPUT_SIZE = 224\n",
        "\n",
        "DYNAMIC_TANH = True\n",
        "DYT_ALPHA_INIT_VALUE = 0.8\n",
        "\n",
        "# optimizer / schedule knobs\n",
        "BATCH_SIZE = 64\n",
        "LR = 4e-3\n",
        "MIN_LR = 1e-6\n",
        "WEIGHT_DECAY = 0.05\n",
        "WARMUP_EPOCHS = 0                # for 10-epoch runs, warmup=0 is usually more sensible than 20\n",
        "WARMUP_STEPS = -1\n",
        "\n",
        "# checkpoint/log dirs\n",
        "OUTPUT_DIR = Path(\"/tmp/vit_dyt_main_cifar100\")\n",
        "LOG_DIR = OUTPUT_DIR / \"tb\"\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- run ---\n",
        "# Build args via the repo's argparse, then call main.main(args)\n",
        "parser = dyt_main.get_args_parser()\n",
        "args = parser.parse_args([\n",
        "    \"--model\", MODEL_NAME,\n",
        "    \"--epochs\", str(EPOCHS),\n",
        "    \"--batch_size\", str(BATCH_SIZE),\n",
        "    \"--lr\", str(LR),\n",
        "    \"--min_lr\", str(MIN_LR),\n",
        "    \"--weight_decay\", str(WEIGHT_DECAY),\n",
        "    \"--warmup_epochs\", str(WARMUP_EPOCHS),\n",
        "    \"--warmup_steps\", str(WARMUP_STEPS),\n",
        "\n",
        "    \"--data_set\", DATA_SET,\n",
        "    \"--data_path\", DATA_PATH,\n",
        "    \"--nb_classes\", str(NB_CLASSES),\n",
        "    \"--input_size\", str(INPUT_SIZE),\n",
        "\n",
        "    \"--output_dir\", str(OUTPUT_DIR),\n",
        "    \"--log_dir\", str(LOG_DIR),\n",
        "\n",
        "    \"--dynamic_tanh\", \"true\" if DYNAMIC_TANH else \"false\",\n",
        "    \"--dyt_alpha_init_value\", str(DYT_ALPHA_INIT_VALUE),\n",
        "\n",
        "    # Save only init + final; no best checkpoints\n",
        "    \"--save_ckpt\", \"true\",\n",
        "    \"--save_init_ckpt\", \"true\",\n",
        "    \"--save_best_ckpt\", \"false\",\n",
        "    \"--save_best_ema_ckpt\", \"false\",\n",
        "    \"--save_ckpt_freq\", str(EPOCHS),\n",
        "    \"--save_ckpt_num\", \"1\",\n",
        "\n",
        "    # keep W&B off by default\n",
        "    \"--enable_wandb\", \"false\",\n",
        "])\n",
        "\n",
        "# Single-process notebook run (no torchrun)\n",
        "dyt_main.main(args)\n",
        "\n",
        "print(\"Done. Logs + checkpoints are in:\", OUTPUT_DIR)\n",
        "print(\"- log.txt:\", OUTPUT_DIR / \"log.txt\")\n",
        "print(\"- init ckpt:\", OUTPUT_DIR / \"checkpoint-init.pth\")\n",
        "print(\"- final ckpt:\", OUTPUT_DIR / f\"checkpoint-{EPOCHS - 1}.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 12: Plot training loss + validation accuracy from main.py's output_dir/log.txt\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "OUTPUT_DIR = Path(\"/tmp/vit_dyt_main_cifar100\")  # must match Cell 11\n",
        "log_path = OUTPUT_DIR / \"log.txt\"\n",
        "\n",
        "epochs = []\n",
        "train_loss = []\n",
        "val_acc1 = []\n",
        "\n",
        "with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        rec = json.loads(line)\n",
        "        epochs.append(int(rec[\"epoch\"]) + 1)\n",
        "        train_loss.append(rec.get(\"train_loss\"))\n",
        "        val_acc1.append(rec.get(\"test_acc1\"))\n",
        "\n",
        "plt.figure(figsize=(7, 3))\n",
        "plt.plot(epochs, train_loss, marker='o')\n",
        "plt.title('Train loss vs epoch')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('train loss')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"train_loss_curve.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7, 3))\n",
        "plt.plot(epochs, val_acc1, marker='o')\n",
        "plt.title('Validation Acc@1 vs epoch')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('val acc@1')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"val_acc1_curve.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved plots to:\")\n",
        "print(\"-\", OUTPUT_DIR / \"train_loss_curve.png\")\n",
        "print(\"-\", OUTPUT_DIR / \"val_acc1_curve.png\")\n",
        "\n",
        "train_loss, val_acc1\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
